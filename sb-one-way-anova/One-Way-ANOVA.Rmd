---
title: "One Way ANOVA"
output: 
 learnr::tutorial:
    progressive: true
    allow_skip: true
    css:
      - https://github.research.chop.edu/pages/CQI/chop-bootstrap/bootstrap-3/bootstrap.min.css
      - https://github.research.chop.edu/pages/CQI/flexdashboard-theme/css/flexdashboard.min.css
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(data.table)
library(dplyr)
library(pwr)
library(tidyr)
library(stats)
library(ggplot2)
library(sortable)
shhh <- suppressPackageStartupMessages
shh <- suppressWarnings
sh <- suppressMessages
knitr::opts_chunk$set(echo = FALSE)
options(digits = 3, scipen = 9999)
tutorial_options(exercise.completion = FALSE,
                 exercise.eval = TRUE,
                 exercise.lines = 8,
                 exercise.diagnostics = TRUE)

Input = ("
Tillamook Newport Petersburg  Magadan Tvarminne
0.0571	0.0873	0.0974	0.1033	0.0703
0.0813	0.0662	0.1352	0.0915	0.1026
0.0831	0.0672	0.0817	0.0781	0.0956
0.0976	0.0819	0.1016	0.0685	0.0973
0.0817	0.0749	0.0968	0.0677	0.1039
0.0859	0.0649	0.1064	0.0697	0.1045
0.0735	0.0835	0.105	  0.0764	NA
0.0659	0.0725	0.0689  NA  NA
0.0923  NA  NA  NA  NA
0.0836  NA  NA  NA  NA
")
mussels <- read.table(textConnection(Input), header = TRUE)
rm(Input)
long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = "location",
                             values_to = "aam")
long_mussels$location <- as.factor(long_mussels$location)
fit <- aov(aam ~ location, long_mussels)

#Create and store a bunch of transformations (tx's)
aam <- long_mussels$aam
log_aam <- log(aam)
log2_aam <- log2(aam)
common_log_aam <- log10(aam)
log1p_aam <- log1p(aam)
log_base_7_aam <- log(aam, base = 7)
aam_squared <- aam^2
aam_cubed <- aam^3
sqrt_aam <- sqrt(aam)
exp_aam <- exp(aam)
expm1_aam <- expm1(aam)

#Make a list of tx's
my_list <- list(aam, log_aam, log2_aam, common_log_aam, log1p_aam, log_base_7_aam,
             aam_squared, aam_cubed, sqrt_aam, exp_aam, expm1_aam)

# Create a function for plotting a single tx.
# Input: one variable
plot_this_tx <- function(this_tx) {
   qplot(data = long_mussels,
      x = this_tx,
      geom = "density")
}

we_are_here <- aam[!is.na(aam) & aam < 0.1352] 
# Create a function for plotting a single tx.
# Input: one variable
plot_this_tx <- function(this_tx) {
   qplot(x = this_tx,
         geom = "density")
}

group_means <- c(10, 10, 15, 15, 15)
experiment_var <- 12^2

power_results <- power.anova.test(groups = 5,
                                   within.var = experiment_var,
                                   between.var = var(group_means),
                                   sig.level = .005,
                                   power = 0.80)

```

## Background

This lesson is both a reference and a tutorial. It contains all the code samples you need to perform a one-way ANOVA on your own data as well as background information such as how to interpret output and which graphs you might want to use to demonstrate results (and in some cases which graphs _not_ to use). 

## What kinds of Variables work with one-way ANOVA

>One [scalar (a.k.a. "measurement") variable](http://www.biostathandbook.com/variabletypes.html#measurement).     
One [nominal (a.k.a. "categorical") variable](http://www.biostathandbook.com/variabletypes.html#nominal)   

The nominal variable divides the measurements into two or more groups. The one-way ANOVA tests whether the means of the measurement variable are the same for the different groups.

## Null and Alternative Hypotheses

>* **H<sub>0</sub>**: The means of the measurement variable are the
same for the different categories in the nominal (a.k.a. "categorical") variable.     
* **H<sub>A</sub>**: The means are not all the same for the different categories in the categorical variable.   

```{r bb, echo=FALSE}
question("Which are examples of a one-way ANOVA null hypotheses?",
         answer("Mean tibia length is the same for each age group of children", correct = TRUE),
         answer("The average monthly electric bill is the same in major cities within the United States", correct = TRUE),
         answer("The average monthly electric bill in Philadelphia, PA is less than what it is in Burlington, VT"),
         answer("The average monthly electric bill in Philadelphia, PA is more than what it is in Burlington, VT"),
         allow_retry = TRUE,
         random_answer_order = TRUE,
         incorrect = "Remember that the one-way ANOVA tests whether the means of the measurement variable are the same for different groups.",
         correct = "Yes!"
)
```

## When to use an ANOVA

Analysis of variance (ANOVA) is the most commonly used technique for __comparing the means of groups__ of measurement data. You can analyze lots of different experimental designs with different kinds of ANOVA. Here we will discuss only the simplest: the _one-way_ ANOVA.

```{r whentouseANOVA, echo=FALSE}
question("Select the cases where ANOVA is appropriate",
         answer("A professor has three classes and you want to compare the professor's assessment of the three classes in comparison with each other"),
         answer("Three professors have one class each and you want to compare the mean class grades", correct = TRUE),
         answer("You want to compare white blood cell counts as a response to medication for four groups of patients", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "You'll learn about independence between groups later, which matters for an ANOVA, but at this point, using common sense, you might be able to figure out why a design that uses only one professor to fill out assessments comparing three classes might introduce bias. Might comparing the classes against each cause a professor to inflate or deflate ratings to rank the classes rather than objectively assess them? And what about the categorical variable? How many categories does the variable `professor` have? If it has only one, then it is not a variable but a constant. Therefore there are not three groups to compare, but just one: and that just won't work."
)
```
<div id="filter-hint">
**Hint:** If you have just one professor and three classes, then the nominal variable (`professor`) is a constant. You need a nominal variable with two or more groups and a [measurement](http://www.biostathandbook.com/variabletypes.html#measurement) variable to perform an ANOVA.
</div>

In a one-way ANOVA (also known as a _one-factor_, _single-factor_, or _single-classification_ ANOVA), there is one measurement variable and one nominal variable. You make multiple observations of the measurement variable for each value of the nominal variable. 

For example, here is some data on a shell measurement (the length of the anterior adductor muscle scar, or AAM length, standardized by dividing by mean length) in the mussel *Mytilus trossulus* from five locations: Tillamook, Oregon; Newport, Oregon; Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland.

```{r data1, echo=FALSE}
mussels
```

The nominal variable is invisible but implicit in the data structure. It's `location`, with the five values `Tillamook`, `Newport`, `Petersburg`, `Magadan`, and `Tvarminne`. There are 6 to 10 observations of the measurement variable, AAM length (`aam`), from each location. Again, `aam` is implicit: you won't find a column called "aam" (until we make one), but all the values in the columns we _do_ have are values for `aam`. The data needs a bit of munging to be ready for analysis. 

```{r select-variables, echo=FALSE}
question("Which _explicit_ variables do we have in the `mussels` data as it is?",
         answer("Tillamook", correct = TRUE),
         answer("Newport", correct = TRUE),
         answer("Petersburg", correct = TRUE),
         answer("Magadan", correct = TRUE),
         answer("Tvarminne", correct = TRUE),
         answer("aam"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "You found them all!",
         incorrect = "The column names in the dataset `mussels` are the variables."
)
```

```{r how-to-modify-data, echo=FALSE}
question("Which variables do we actually want to analyze?",
         answer("location", correct = TRUE),
         answer("aam", correct = TRUE),
         answer("country"),
         answer("city"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "That's right. Just two variables will do the trick.",
         incorrect = "You need two variables as described in the paragraph above these two questions."
)
```


## How to Prepare your Data for a one-way ANOVA in R

You should, before any call to a statistical function, ensure that the data is in the correct format for running the analysis. For an ANOVA, remember, you should have one [nominal (a.k.a. "categorical") variable](http://www.biostathandbook.com/variabletypes.html#nominal) variable with 2 or more categories and one [measurement (a.k.a. "scalar")](http://www.biostathandbook.com/variabletypes.html#measurement) variable. 

Start by looking at the data again.

```{r look-at-mussels-again, exercise = TRUE, exercise.lines = 5}

```
```{r look-at-mussels-again-solution}
mussels
```

To use the language of `tidyverse`'s `gather` and `spread` functions, we have a bunch of "key" variables that should actually be levels in a `location` variable. And we have a bunch of "values", anterior adductor muscle (AAM) scar lengths, that should actually be the `aam` variable. 

To summarize, we will convert the implicit variable `location` into a _factor_ variable and the implicit variable `aam` into a _scalar_ variable. 

The terms "key" and "value" as used in `gather` and `spread` have proven difficult to communicate to many R users. The folks who created the `tidyverse` therefore set up some new functions, `pivot_longer` and `pivot_wider`, that they hoped would prove easier for people to understand. The `gather` and `spread` functions aren't being maintained any more. You might have learned them elsewhere, but you may want to learn the new functions now. 

```{r gather-pivot, echo=FALSE}
question("Which function replaces the `gather` function in the `tidyverse`?",
         answer("pivot_longer", correct = TRUE),
         answer("pivot_wider"),
         answer("bring_together"),
         answer("find_implicit_variable"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "You are amazing!",
         incorrect = "Rather than gathering variables, Wickham & co. decided that 'pivot' was more intuitive. Perhaps it will help to think about which way gathering extends variables: along the _x_ axis or along the _y_ axis?"
)
```

So your first step may be to check out our lesson about [pivot_longer](../sb-pivot-longer/), if you haven't used it before, to transform a wide data set to a narrower, longer one. Your work will still be here when you get back. 

#### Convert Wide Data to Long Data by using `pivot_longer`

Using the method from [Pivot Longer](../sb-pivot-longer/), enter the code for making the the wide version of `mussels` longer here. Store the output from your call to `pivot_longer` in `long_mussels`. 

Remember to set the new `location` variable in `long_mussels` to be a factor once you've created `long_mussels`.

If you haven't time to do the [pivot_longer](../sb-pivot-longer/) lesson, use the Hints buttons to teach yourself the proper syntax for the `pivot_longer` function.

Make sure you enclose your assignment commands in parentheses so you can see what they are doing without having to add another line to display results. 

```{r pivot-in-prep-for-anova, exercise = TRUE, exercise.lines = 10}

```
```{r pivot-in-prep-for-anova-hint-1}
long_mussels <- pivot_longer(data = ...,
                             cols = ...)
```
```{r pivot-in-prep-for-anova-hint-2}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(...)))
```
```{r pivot-in-prep-for-anova-hint-3}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = ...,
                             values_to = ...))
```
```{r pivot-in-prep-for-anova-hint-4}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = "location",
                             values_to = "aam"))
```
```{r pivot-in-prep-for-anova-solution}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = "location",
                             values_to = "aam"))
(long_mussels$location <- as.factor(long_mussels$location))
```

Now you have a beautiful data set with the two variables of interest. One variable is a factor (a categorical or nominal variable) and the other is a scalar or measurement variable. Now let's visualize this data set.

## Data Visualization for an ANOVA

As is typical with R, there are many ways to visualize the data. I'll show you two of the easiest here.

### Quickly Visualize the Data with a Boxplot

You can quickly visualize `long_mussels` with a `boxplot` using the R formula interface (`aam ~ location`) in a call to `boxplot`. Send `boxplot` that formula and tell it that the data is `long_mussels`. 

```{r boxplot, fig.width = 9, exercise = TRUE, exercise.lines = 5}

```
```{r boxplot-hint-1}
boxplot(...)
```
```{r boxplot-hint-2}
boxplot(aam ~ ..., ...)
```
```{r boxplot-hint-3}
boxplot(aam ~ location, data = ...)
```
```{r boxplot-solution, fig.width = 9}
boxplot(aam ~ location, data = long_mussels)
```

You now have a beautiful, clean visualization to provide along with the results of your ANOVA.

```{r predict-the-finding, echo=FALSE}
question("Looking at the boxplot you just made, what do you think the results of an ANOVA will be?",
         answer("Not all the means are the same among locations.", correct = TRUE),
         answer("All the means are the same among locations.", message = "It's pretty clear from the boxplot that at least one `location` mean is different from at least one other `location` mean."),
         answer("Petersburg and Tvarminne have the same means", message = "Although an ANOVA tells us whether _any_ pairs of means differ from each other, it doesn't tell us _which_ pairs. You need a _post hoc_ test to get that additional information."),
         answer("There are two groups of `aam` values", message = "Although you can see clear groups in the boxplot, an ANOVA does not tell you anything about groups. It tells you only that some means differ. You can run a _post hoc_ test to find out more about groupings."),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "Unfortunately, no.",
         correct = "You got it!"
)
```

To learn more about base plotting, see our lessons [Base Graphics](../swirl-base-graphics/) and [Base Plotting System](../swirl-base-plotting-system/). For a discussion of data visualization principles, see [Principles of Analytic Graphs](../swirl-principles-of-analytic-graphs/). To learn how to plot in `ggplot2`, see [`ggplot2` Part 1](../swirl-ggplot2-part-1/), [`ggplot2` Part 2](../swirl-ggplot2-part-2/), [`ggplot2` Extras](../swirl-ggplot2-extras/), and [Exploratory Graphs](../swirl-exploratory-graphs/).

### Quickly Visualize the Data with a Density Plot

Sometimes the most accurate way to compare levels of a variable against each other for the purpose of illustrating your ANOVA is by creating a density plot (which, at one point, was called a "joyplot"). 

`qplot` is a very handy way to use `ggplot2` quickly to create a plot. Place `ggplot2` in the library, then construct your call to `qplot` by passing 6 items to it:

* `data` set equal to `long_mussels`    
* `x` set equal to the variable `aam`    
* `geom` set equal to the string "density"    
* `color` set equal to the variable `location`    
* `fill` also set equal to the variable `location`    
* `alpha` set equal to .25

```{r qplot-density, exercise = TRUE, exercise.lines = 10}

```
```{r qplot-density-hint-1}
library(ggplot2)
qplot(...)
```
```{r qplot-density-hint-2}
library(ggplot2)
qplot(data = long_mussels, ...)
```
```{r qplot-density-hint-3}
library(ggplot2)
qplot(data = long_mussels, 
      x = aam, 
      geom = "density", ...)
```
```{r qplot-density-hint-4}
library(ggplot2)
qplot(data = long_mussels, 
      x = aam, 
      geom = "density", 
      color = location,
      fill = location, ...)
```
```{r qplot-density-solution}
library(ggplot2)
qplot(data = long_mussels, 
      x = aam, 
      geom = "density", 
      color = location,
      fill = location,
      alpha = .25)
```

```{r which-is-bi-modal, echo=FALSE}
question("From which location did we get bi-modal data with a small mode in the lower values and a large mode in the upper values?",
         answer("Magadan"),
         answer("Newport"),
         answer("Petersburg"),
         answer("Tillamook"),
         answer("Tvarmine", correct = TRUE),
            random_answer_order = TRUE,
            allow_retry = TRUE,
         correct = "That's right!",
         incorrect = "Look again. It's pink."
)
```
```{r meaning-of-bi-modal-data-in-small-data-set, echo=FALSE}
question("With what information have our data visualizations provided us, given how few measurements we have and also given the fact that the data is imabalanced (i.e., we have fewer readings from some locations than from others)?",
         answer("Nothing", message = "Although some might agree that the data is useless, we beg to differ."),
         answer("Perhaps some hints about what kind of data to gather next", correct = TRUE),
         answer("Since an ANOVA is robust to imbalanced design, the answer to whether the group means differ in the underlying populations of mussels for these locations", message = "A one-way ANOVA is _not_ robust to imbalanced design, especially if the standard deviations are different among the groups"),
         answer("Data distributions in our specific data sets", correct = TRUE),
         answer("Data distributions in the underlying populations at these locations", message = "You would need a hypothesis test to draw such a conclusion."),
            random_answer_order = TRUE,
            allow_retry = TRUE,
         correct = "Yes! Even when a test has its problems, you can use it to direct your attention to the next step in your research process. Do you need to gather more data? Ask a slightly different question and gather the data for that? Further, we see what our _specific_ data looks like, which can be helpful, even if we can't make any inferences about the underlying population of mussels.",
         incorrect = "No."
)
```

Many people choose to show their data as boxplots because boxplots are usually cleaner visualizations. However, the density plot provides good information about our data:

* Tvarminne is bi-modal    
* Not all the levels are normally distributed    
* 11 rows were deleted due to missingness, which means that not all the levels of `location` contain the same number of observations. 

Some of the problems we see are common in small data sets. The fact that we lost 11 rows is also interesting: are we sure we have designed the experiment properly? 

What is alpha? See [`ggplot2` Part 1](../swirl-ggplot2-part-1/), [`ggplot2` Part 2](../swirl-ggplot2-part-2/), [`ggplot2` Extras](../swirl-ggplot2-extras/) to find out. But you can also guess.

```{r what-is-alpha, echo=FALSE}
question("What is `alpha` in the code for the density plot above?",
         answer("A value that tells us what is the cutoff for 'alpha variables'"),
         answer("The family of the colors to use"),
         answer("Color opacity", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Excellent!",
         incorrect = "Nope. Try again."
)
```

If this plot makes you wonder whether our data violates assumptions of ANOVA, then you are thinking like a data scientist! We'll talk more about assumptions later in this lesson.

Meanwhile, we soldier on. 

## ANOVA Assumptions and How to Check Them

All statistical tests rest upon assumptions about your data. In order to perform proper statistical analysis, you need to know what assumptions you are making and you need to be certain that none of your assumptions violate the assumptions of the one-way ANOVA. 

### Assumption: The Residuals are Normal

The one-way ANOVA assumes that **the residuals of the observations within each group are normally distributed**.


```{r where_resids, echo=FALSE}
question("HARD QUESTION: Where can you get a copy of the residuals in `long_mussels$aam`?",
         answer("Calculate them by hand", message = "Just... no."),
         answer("Run a regression analysis and hope they show up", message = "You could and they would, but if you think back, you already ran a linear model when you ran `aov` on the `long_mussel` data set. Try typing `str(fit)` (say 'structure of fit` in your head) to find out what is being stored in the model you got back from that procedure."),
         answer("They are in `fit`, which you already created if you have been doing this tutorial step by step", correct = TRUE),
         answer("Wherever lost socks go", message = "Really?"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Well done!",
         incorrect = "No."
)
```


You actually don't need to find the residuals. Instead, simply use `qqnorm` to make a qqplot. It calculates the residuals for you. 

Try it now. Pass `long_mussels$aam` to `qqnorm`, then pass it again to `qqline`. If you can figure out how, make the line red and give it a width of 2. HINT: Type `?qqline` at the prompt or just peek at the hints.

```{r qqnormaam, exercise = TRUE, exercise.lines = 5}

```
```{r qqnormaam-hint-1}
qqnorm(...)
```
```{r qqnormaam-hint-2}
qqnorm(long_mussels$aam)
```
```{r qqnormaam-hint-3}
qqnorm(long_mussels$aam)
qqline(...)
```
```{r qqnormaam-solution}
qqnorm(long_mussels$aam)
qqline(long_mussels$aam, col = "red", lwd = 2)
```

`qqnorm` checks the residuals (the $\displaystyle y$ axis) against what the same data points would be if they were normally distributed (the $\displaystyle x$ axis). Many statisticians use the "fat pencil rule" to decide whether the data points are close enough to the line to count as normally distributed. Imagine yourself laying a fat pencil along the red line. Does it cover all the dots? If so, you're good. 

This distribution of residuals is right on the edge of acceptable. Let's pretend it's not acceptable to learn what we can do about it.

#### What to do When the Residuals Are not Normally Distributed

Extensive simulations demonstrate that ANOVA is _not_ particularly sensitive to deviations from the assumption of normality; if you perform a one-way ANOVA on data with residuals that are non-normal, your chance of getting a _p_ value less than 0.05, if the null hypothesis is true, is still pretty close to 0.05. Nonetheless, it’s better if your data are close to normal. 

Our next step is to transform the data to see if we can get a better set of residuals. 

If you don't know what a transformation is, try guessing.

```{r what-is-a-transformation, echo=FALSE}
question("Which of these can be used to transform scalar data points?",
         answer("take the natural log", correct = TRUE),
         answer("square them", correct = TRUE),
         answer("cube them", correct = TRUE),
         answer("take the square root", correct = TRUE),
         answer("take the cube root", correct = TRUE),
         answer("add 1 to them", correct = TRUE),
         answer("perform a _z_ transformation", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "That's right. Basically anything you can do to a number can operate as a transformation of your data. Some transformations are more useful than others, but you can _try_ anything.",
         incorrect = "Keep trying. Does a square root transform a number? Does adding 1 to it transform it?"
)
```

Just for fun, try transformating `long_mussels$aam` in various ways in the sandbox that follows. Send your transformationed data, as well as the non-transformed data, to `qplot` (see our [swirl `ggplot2` Part 1 lesson](../swirl-ggplot2-part-1/) to learn about `qplot`) to find out whether any of your transformations normalize your data. HINT: To take the natural log of a scalar variable, use `log(a_scalar_variable)`. `log` is in the base stats package. Type `?log` in the sandbox to learn how to play with other logarithms and with exponents. 

You can use your own ideas or follow the code in the hints. The code I wrote includes what you can (or already did) learn in [swirl Part 4 - Vectors](../swirl-vectors/), [swirl Part 9 - Functions](../swirl-functions), [swirl Part 10 - `lapply` and `sapply`](../swirl-lapply-and-sapply/) and  [`ggplot2` Part 1](../swirl-ggplot2-part-1/). If my code doesn't make sense to you, try revisiting those lessons. 

```{r practice-tx, exercise = TRUE, exercise.lines = 25}

```
```{r practice-tx-hint-1}
aam <- long_mussels$aam
```
```{r practice-tx-hint-2}
aam <- long_mussels$aam
log_aam <- log(aam)
log2_aam <- log2(aam)
common_log_aam <- log10(aam)
log1p_aam <- log1p(aam)
log_base_7_aam <- log(aam, base = 7)
aam_squared <- aam^2
aam_cubed <- aam^3
sqrt_aam <- sqrt(aam)
exp_aam <- exp(aam)
expm1_aam <- expm1(aam)
```
```{r practice-tx-hint-3}
aam <- long_mussels$aam
log_aam <- log(aam)
log2_aam <- log2(aam)
common_log_aam <- log10(aam)
log1p_aam <- log1p(aam)
log_base_7_aam <- log(aam, base = 7)
aam_squared <- aam^2
aam_cubed <- aam^3
sqrt_aam <- sqrt(aam)
exp_aam <- exp(aam)
expm1_aam <- expm1(aam)
my_list <- c(aam, log_aam, log2_aam, common_log_aam, log1p_aam, log_base_7_aam,
             aam_squared, aam_cubed, sqrt_aam, exp_aam, expm1_aam)
```
```{r practice-tx-hint-4}
#Create and store a bunch of transformations (tx's)
aam <- long_mussels$aam
log_aam <- log(aam)
log2_aam <- log2(aam)
common_log_aam <- log10(aam)
log1p_aam <- log1p(aam)
log_base_7_aam <- log(aam, base = 7)
aam_squared <- aam^2
aam_cubed <- aam^3
sqrt_aam <- sqrt(aam)
exp_aam <- exp(aam)
expm1_aam <- expm1(aam)

#Make a list of tx's
my_list <- c(aam, log_aam, log2_aam, common_log_aam, log1p_aam, log_base_7_aam,
             aam_squared, aam_cubed, sqrt_aam, exp_aam, expm1_aam)

# Create a function for plotting a single tx
plot_this_tx <- function(this_tx) {
   qplot(data = long_mussels,
      x = this_tx,
      geom = "density")
}


```
```{r practice-tx-solution}
#Create and store a bunch of transformations (tx's)
aam <- long_mussels$aam
log_aam <- log(aam)
log2_aam <- log2(aam)
common_log_aam <- log10(aam)
log1p_aam <- log1p(aam)
log_base_7_aam <- log(aam, base = 7)
aam_squared <- aam^2
aam_cubed <- aam^3
sqrt_aam <- sqrt(aam)
exp_aam <- exp(aam)
expm1_aam <- expm1(aam)

#Make a list of tx's
my_list <- list(aam, log_aam, log2_aam, common_log_aam, log1p_aam, log_base_7_aam,
             aam_squared, aam_cubed, sqrt_aam, exp_aam, expm1_aam)

# Create a function for plotting a single tx.
# Input: one variable
plot_this_tx <- function(this_tx) {
   qplot(data = long_mussels,
      x = this_tx,
      geom = "density")
}

# Now use lapply to apply the plot function to each element in my list
lapply(my_list, plot_this_tx)
```

Now take the list of transformed copies of `aam` and `lapply` `qqnorm` and `qqline` to it. HINT: Create a function that does both `qqnorm` and `qqline` to whatever you pass it.

```{r lapply-qqnorm-qqline, exercise = TRUE, exercise.lines = 5}

```
```{r lapply-qqnorm-qqline-hint}
qq_this_tx <- function(this_tx) {
   ...
}
lapply(...)
```
```{r lapply-qqnorm-qqline-solution}
qq_this_tx <- function(this_tx) {
   qqnorm(this_tx)
   qqline(this_tx, col = "red", lwd = 2)
}
lapply(my_list, qq_this_tx)
```

#### Soapbox: The Outlier

```{r did-you-notice, echo=FALSE}
question("Did you notice the outlier?",
         answer("Yes", correct = TRUE),
         answer("No"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Excellent.",
         incorrect = "No? Go back and look at the results of `qqnorm`."
)
```

No, you can't just delete it. Don't get me started.

Too late: Let's talk about the outlier. 

It's having an impact on the data set. Create a variable called `we_are_here` and assign to it `aam[!is.na(aam) < 0.135]` (all the members of `aam` that return `TRUE` for not being missing _and_ that are less than 0.135). The outlier has a value of 0.1352, so this [logic](../swirl-logic/) will exclude it. Then pass `we_are_here` to `qqnorm` and `qqline` (with the same parameters as before).

```{r we-are-here, exercise = TRUE, exercise.lines = 5}

```
```{r we-are-here-hint-1}
we_are_here <- ?
```
```{r we-are-here-hint-2}
we_are_here <- aam[!is.na(aam) & aam < 0.1352] 
qqnorm(...)
qqline(..)
```
```{r we-are-here-hint-3}
we_are_here <- aam[!is.na(aam) & aam < 0.1352] 
qqnorm(we_are_here)
qqline(...)
```
```{r we-are-here-hint-4}
we_are_here <- aam[!is.na(aam) & aam < 0.1352] 
qqnorm(we_are_here)
qqline(we_are_here, ..., ...)
```
```{r we-are-here-solution}
we_are_here <- aam[!is.na(aam) & aam < 0.1352] 
qqnorm(we_are_here)
qqline(we_are_here, col = "red", lwd = 2)
```

```{r better-or-worse, echo=FALSE}
question("Does the new qqplot look better or worse?",
         answer("Kinda better"),
         answer("Kinda worse", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Mmhm.",
         incorrect = "Kinda not really."
)
```

Lesson learned: It doesn't necessarily help to get rid of outliers. 

But there's more to it than that. Unless you have reason to believe the outlier is an erroneous measurement, leave it alone. If it's true, it's data. We don't trim outliers even if certain statistical programs (we name no names) give you the option to do so.

Here's some code for checking to see if any of the transformations works better with the outlier gone.

```{r practice-tx-take-2, echo = TRUE, include = TRUE}
#Create and store a bunch of transformations (tx's)
log_we_are_here <- log(we_are_here)
log2_we_are_here <- log2(we_are_here)
common_log_we_are_here <- log10(we_are_here)
log1p_we_are_here <- log1p(we_are_here)
log_base_7_we_are_here <- log(we_are_here, base = 7)
we_are_here_squared <- we_are_here^2
we_are_here_cubed <- we_are_here^3
sqrt_we_are_here <- sqrt(we_are_here)
exp_we_are_here <- exp(we_are_here)
expm1_we_are_here <- expm1(we_are_here)

#Make a list of tx's
my_list2 <- list(we_are_here, log_we_are_here, log2_we_are_here, common_log_we_are_here, 
                 log1p_we_are_here, log_base_7_we_are_here, we_are_here_squared,
                 we_are_here_cubed, sqrt_we_are_here, exp_we_are_here, expm1_we_are_here)

# Now use lapply to apply the plot function to each element in my list
lapply(my_list2, plot_this_tx)
```

See? It wasn't worth it. We gained nothing; in fact we caused the bimodal nature of the data set become more of an issue.

Don't. Delete. Outliers. (Unless they are wrong. Dead wrong. As in input wrong.)

### If no Transformations Produce Normally Distributed Residuals

If none of the transformations you tried made the data look _normal_ _enough_, you have a couple of choices: run the ANOVA anyway or use
the [Kruskal-Wallis test](../sb-kruskal-wallis/). Be aware of these factors if you decide to performa a Kruskal-Wallis test:

* the Krusal-Wallis test makes the assumption that the different groups
have the same shaped distributions (which we know already isn't true because we did a density plot earlier in this lesson that showed that the shapes of the distributions for each level of `location` are different)    
* the Krusal-Wallis test doesn’t test the same null hypothesis as
the one-way ANOVA    

Personally, we don’t like the Kruskal-Wallis test; We recommend that if you
have non-normal data that can’t be fixed by transformation, you go ahead and use one-way
ANOVA; but be cautious about rejecting the null hypothesis if the _p_ value is not very far
below 0.05 and if your data is extremely non-normal. You may even want to set alpha to something besides .05, say, .005 (see [Reassessing p Values](../sb-reassessing-p-values/) for why this particular number might be a good choice).

```{r whynot-kw, echo=FALSE}
question("Why might the Kruskal-Wallis test NOT be a good non-parametric substitute for a one-way ANOVA?",
         answer("Because it has a different null hypothesis than the one-way ANOVA", correct = TRUE),
         answer("Because it relies on a homoscedastic scalar variable across all the groups in the categorical variable", correct = TRUE),
         answer("Because we find it personally offensive"),
         answer("Because it is best designed for truly ranked data (like grade levels), not just non-parametric data; translating data from values to ranks causes a loss of precision. Hence it is a poor substitute for a one-way ANOVA, even if that ANOVA is a bit wobbly", correct = TRUE),
            random_answer_order = TRUE,
            allow_retry = TRUE,
         correct = "You are amazing!",
         incorrect = "Check out the Kruskal-Wallis lesson (linked above) to learn more, and read the paragraph just above this question."
)
```

### Assumption: Homoscedasticity

A one-way ANOVA assumes that your data are homoscedastic, meaning the standard
deviations are equal in the groups. You should examine the standard deviations in the
different groups and see if there are big differences among them. Try that now with `mussels`. Use `sapply` to check the standard deviation (SD) for each column of `mussels`. Remember that the function `sd` needs to know what to do with `NA`s. Wrap the whole function call in a call to `range`. 

```{r checksd, exercise = TRUE, exercise.lines = 5}

```
```{r checksd-hint-1}
range(...)
```
```{r checksd-hint-2}
range(sapply(...))
```
```{r checksd-hint-3}
range(sapply(mussels, ...))
```
```{r checksd-hint-4}
range(sapply(mussels, sd, ..))
```
```{r checksd-solution}
range(sapply(mussels, sd, na.rm = TRUE))
```

```{r times3, echo=FALSE}
question("Is the highest standard deviation at least 3 times the lowest?",
         answer("Yes"),
         answer("No", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "You can use the R console in any code box as a calculator."
)
```

If you have a balanced design, meaning that the number of observations (_n_) is the same in
each group, then a one-way ANOVA is not very sensitive to heteroscedasticity (different
standard deviations in the different groups). As of this writing, McDonald, from whom we have liberally borrowed (with permission) for this lesson, hasn't found a thorough study of the
effects of heteroscedasticity that considered all combinations of the number of groups,
sample size per group, and amount of heteroscedasticity. He has done simulations with two
groups, and they indicated that heteroscedasticity will give an excess proportion of false
positives for a balanced design _only_ if one standard deviation is at least three times the
size of the other, _and_ the sample size in each group is fewer than 10. I would guess that a
similar rule would apply to one-way ANOVAs with more than two groups and balanced
designs.

```{r when-het-is-bad, echo=FALSE}
question("When is heteroscedasticity really, really bad for an ANOVA?",
         answer("When the design is also imbalanced", correct = TRUE),
         answer("All the time"),
         answer("Right now"),
         answer("Next week"),
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

The difference in
standard deviations between groups does not have to be large to create problems; a smaller group could have a standard
deviation that’s 50% larger, and your rate of false positives could be above 10% instead of
at 5% where it belongs. If the groups with larger sample sizes have larger standard
deviations, the error is in the opposite direction; you get too _few_ false positives, which
might seem like a good thing except it also means you lose power (get too many
negatives even if there _is_ a difference in means).

You should try really hard to have equal sample sizes in all of your groups. With a
balanced design, you can safely use a one-way ANOVA unless the sample sizes per group
are less than 10 _and_ the standard deviations vary by threefold or more. If you have a
balanced design with small sample sizes and very large variation in the standard
deviations, you should use Welch’s ANOVA instead.

If you have an unbalanced design, you should carefully examine the standard
deviations. Unless the standard deviations are very similar, you should probably use
Welch’s ANOVA. It is less powerful than one-way ANOVA for homoscedastic data, but it can
be much more accurate for heteroscedastic data from an unbalanced design.


## Perform the ANOVA 

The `lm` function in the native `stats` package fits a linear model by [least squares](https://rcompanion.org/handbook/G_05.html), and can be used for a variety of analyses: [regression](../sb-correlation-and-linear-regression/), analysis of variance (what we're doing now), and [analysis of covariance](https://rcompanion.org/rcompanion/e_04.html), for instance.  The analysis of variance is then conducted either with the `anova` function in the `car` package for [Type II or Type III sum of squares](https://rcompanion.org/rcompanion/d_04.html), or with the `aov` function in the native `stats` package for [Type I sum of squares](https://rcompanion.org/rcompanion/d_04.html). 

```{r where-can-we-use-lm, echo=FALSE}
question("Which analyses can you do using the `lm` function?",
         answer("linear regression", correct = TRUE),
         answer("analysis of variance", correct = TRUE),
         answer("analysis of covariance", correct = TRUE),
         answer("Kruskal-Wallis test"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "`lm` is amazing. And so are you!",
         incorrect = "Doing a Kruskal-Wallis test with `lm` would be a bit like vacuuming with a wet mop: It's just not done, for very good reasons."
)
```

```{r two-functions-to-do-anova, echo=FALSE}
question("Which two functions can you use to run an analysis of variance?",
         answer("`stats`", message = "`stats` is a package, not a function."),
         answer("`aov`", correct = TRUE),
         answer("`lm`", correct = TRUE),
         answer("`car`", message = "`car` is a package, not a function."),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "",
         correct = "You got it!"
)
```
```{r two-packages-to-do-anova, echo=FALSE}
question("Name two packages that can you use to run an analysis of variance (of course there are more---this is R).",
         answer("`stats`", correct = TRUE),
         answer("`anova`", message = "`anova` is a function, not a package."),
         answer("`lm`", message = "`lm` is a function, not a package."),
         answer("`car`", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "",
         correct = "All your hard work is paying off!"
)
```

The simplest way to perform the analysis of variance procedure is using `aov` from the native `stats` package, accepting all its defaults. To see what the defaults are, type `?aov` at the command line.

Try running `aov` here. First, make sure that you have `stats` in the library. 

Next, store the results of your call to `aov` (which calls `lm`, among other things) in the variable `fit`. Pass `aov` the formula of interest (the measurement variable "across" or `~` the categorical variable) and the name of the data set in the form `data = long_mussels`. 

Finally, use `summary(fit)` to see the results. 

```{r aov-for-fun, exercise = TRUE, exercise.lines = 5}

```
```{r aov-for-fun-hint-1}
library(stats)
fit <- ?
summary(fit)
```
```{r aov-for-fun-hint-2}
library(stats)
fit <- aov(...)
summary(fit)
```
```{r aov-for-fun-solution}
library(stats)
fit <- aov(aam ~ location, data = long_mussels)
summary(fit)
```

(Hint: If you don't see any results, make sure you have asked to see a `summary` of `fit`.)

What does all this mean? Most people quickly focus on the _p_ value, which here is .0036. Apparently we can reject the null hypothesis that the means among the groups are the same. 

We also have more information: the test statistic $\displaystyle F$ (4.78), the degrees of freedom (4, 34), and the sums of the squares and the mean square values for location and for the residuals. When you report ANOVA results, you typically report $\displaystyle F$, the degrees of freedom, and the $\displaystyle p$ statistic.

```{r what-to-report, echo=FALSE}
question("Which of these numbers do you include when you report the results of an ANOVA?",
         answer("_p_", correct = TRUE),
         answer("_F_", correct = TRUE),
         answer("df", correct = TRUE),
         answer("the mean squares"),
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

Take note of the fact that 11 observations were deleted due to missingness. The levels do not all have the same number of values in them. Is this a problem? Perhaps. You can review this question in the section [ANOVA Assumptions and how to Check Them](https://reslnarcusedu01.research.chop.edu/sb-one-way-anova/#section-anova-assumptions-and-how-to-check-them).

Just for fun, run `aov` and allow the results to print without first storing them in `fit` and using `summary` to format them.

```{r aov-again, exercise = TRUE, exercise.lines = 5}

```
```{r aov-again-hint-1}
library(stats)
aov(...)
```
```{r aov-again-hint-2}
library(stats)
aov(aam ~ location, ...)
```
```{r aov-again-solution}
library(stats)
aov(aam ~ location, data = long_mussels)
```

This provides less information than when we summarized `fit`! That's why people usually do summarize whatever fit they get from `lm` or `aov`. 

```{r two-ways-to-summarize-fit, echo=FALSE}
question("Which lines of code result in a summary of the fit for an ANOVA?",
         answer("`summary(aov(aam ~ location, data = long_mussels))`", correct = TRUE),
         answer("`fit <- aov(aam ~ location, data = long_mussels); summary(fit)`", correct = TRUE),
         answer("`fit <- aov(aam ~ location, data = long_mussels)`"),
         answer("`aov(aam ~ location, data = long_mussels)`"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "Here's a hint: In R, you can put multiple commands on the same line using `;` to separate them.",
         correct = "You are amazing!"
)
```

## You found something interesting! Now what?
 
If the analysis of variance indicates an interesting effect of the independent variable (here, `location`), you can conduct multiple comparisons _among_ the levels of this factor using Tukey-Kramer or Least Significant Difference (LSD) procedures. (The problem of inflating the Type I Error Rate when making multiple comparisons is discussed in the [Multiple Comparisons chapter](http://www.biostathandbook.com/multiplecomparisons.html) in John H. McDonald's [Handbook of Biological Statistics](http://www.biostathandbook.com/chigof.html))  

R functions that make multiple comparisons usually allow for adjusting _p_ values. In R, you can use the Benjamini–Hochberg (BH) or `fdr` procedure. See `?p.adjust` for more information.

Let's take a quick look at one method for identifying _which_ pairs of means differ from each other. 

## Tukey-Kramer _post hoc_ Test

One common way to look at the data in more detail after performing an ANOVA is to compare different pairs of means and see which are significantly different from each other. For the mussel shell
example, the overall _p_ value piques our interest. We therefore want to follow up
by asking whether the mean in Tillamook is different from the mean in Newport, whether
Newport is different from Petersburg, and so on.

```{r what-does-tukey-kramer-do, echo=FALSE}
question("What does the Tukey-Kramer test tell you?",
         answer("Which pairs of group means are different from each other.", correct = TRUE),
         answer("Whether the critic Tukey liked the movie _Kramer vs. Kramer_.", message = "Really?"),
         answer("Whether the non-parametric ANOVA is also significant.", message = "I'm afraid not."),
         answer("Whether the ANOVA was significant under the assumptions.", message = "No, the Tukey-Kramer test doesn't say anything about assumptions. In fact, even we haven't said anything about assumptions yet. We'll get there, though."),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Perfect!",
         incorrect = ""
)
```

It might be tempting to use a simple two-sample t–test on each pairwise comparison
that looks interesting to you. However, this can result in a lot of false positives. When
there are a groups, there are $\displaystyle \frac{a^2 -a}{2}$ possible pairwise comparisons, a number that quickly
increases as the number of groups increases:

* With 5 groups, you would have 10 pairwise comparisons     
* With 10 groups, you would have 45     
* With 20 groups, you would have 190 pairs    

When you do multiple comparisons, you increase the probability that at least one will have a _p_ value less than 0.05 purely by chance, _even if_ the null hypothesis of each comparison is true.

There are a number of different tests for pairwise comparisons after a one-way ANOVA,
and each has advantages and disadvantages. The differences among their results are fairly
subtle, so I will describe only one, the Tukey-Kramer test. 


The Tukey-Kramer test is probably the most
commonly used post-hoc test used with a one-way ANOVA, and it is fairly easy to understand.


In the Tukey–Kramer method, the minimum significant difference (MSD) is calculated
for each pair of means. It depends on the sample size in each group, the average variation
within the groups, and the total number of groups. For a balanced design, all of the MSDs
will be the same; for an unbalanced design, pairs of groups with smaller sample sizes will
have bigger MSDs. If the observed difference between a pair of means is greater than the
MSD, the pair of means is significantly different. 

Perform the analysis with the `TukeyHSD` function from the `stats` package. You already have a model in the variable `fit`. Pass it to `TukeyHSD` and see what happens. Use the questions below to help you decode the results. 

```{r tukeyHSD, exercise = TRUE, exercise.lines = 5}

```
```{r tukeyHSD-hint-1}
TukeyHSD(...)
```
```{r tukeyHSD-solution}
TukeyHSD(fit)
```

```{r how-to-interpret-tukey, echo=FALSE}
question("How do you interpret `Newport-Magadan      -0.004514` (which should be in your `TukeyHSD` output)",
         answer("The _p_ value is a negative number."),
         answer("The confidence interval contains 0."),
         answer("If you subtract Magadan's mean from Newport's, you would get -0.004514.", correct = TRUE),
            random_answer_order = TRUE,
            allow_retry = TRUE,
         correct = "That's correct!"
)
```

```{r conf-interval, echo=FALSE}
question("What are the confidence interval bounds for Tillamook-Petersburg?",
         answer("[-0.024872, 0.015843]"),
         answer("[-0.018925, -0.037583]"),
         answer("[-0.037583, -0.00026]", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "You are doing so well!"
)
```

```{r identify-sig-diffs, echo=FALSE}
question("Which differences have _p_ < .05?",
         answer("Newport-Magadan"),
         answer("Petersburg-Magadan"),
         answer("Tillamook-Magadan"),
         answer("Petersburg-Newport", correct = TRUE),
         answer("Tillamook-Newport"),
         answer("Tillamook-Petersburg", correct = TRUE),
         answer("Tvarminne-Petersburg"),
         answer("Tvarminne-Tillamook"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "You got it!"
)
```

## Welch’s ANOVA

If the data show a lot of heteroscedasticity (different groups have different standard
deviations), the one-way ANOVA can yield an inaccurate _p_ value; the probability of a false
positive may be much higher than 5%. In that case, you could use Welch’s ANOVA. If, in addition, the different groups have different _n_s, you _should_ use a Welch's ANOVA instead of a one-way.  

```{r when-to-use-welches, echo=FALSE}
question("Under what conditions should you use a Welch's ANOVA instead of a classic one-way ANOVA?",
         answer("When different groups have different standard deviations (i.e., the data is heteroscedastic)", correct = TRUE),
         answer("When different groups have different _n_s", correct = TRUE),
         answer("Whenever the probability of a false positive is greater than 5%"),
         answer("When you have a small data set with homoscedastic data"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "You got it right!",
         incorrect = "Keep trying. Remember that the one-way ANOVA is not robust to an imbalanced design and it rests upon the assumption that group standard deviations are roughly similar."
)
```

Use the the `oneway.test` function from the `stats` package for a Welch's ANOVA. Whenever you set `var.equal` equal to `FALSE`, `oneway.test` runs the Welch's test. 

Try it now following these steps:

1. Ascertain that the `stats` package is in the library.    
2. Call `oneway.test` and pass it these arguments:    
   * the formula `aam ~ location`, as usual    
   * the name of the dataset (`long_mussels`)       
   * the argument `var.egual` set equal to `FALSE`    

```{r welch-anova, exercise = TRUE, exercise.lines = 5}

```
```{r welch-anova-hint-1}
oneway.test(...)
```
```{r welch-anova-hint-2}
oneway.test(aam ~ location, 
            ...)
```
```{r welch-anova-hint-3}
oneway.test(aam ~ location, 
            data = long_mussels, 
            ...)
```
```{r welch-anova-hint-4}
oneway.test(aam ~ location, 
            data = long_mussels, 
            var.equal = ...)
```
```{r welch-anova-solution}
oneway.test(aam ~ location, 
            data = long_mussels, 
            var.equal = FALSE)
```

```{r did-welchs-show-something, echo=FALSE}
question("Do the results of your Welch's ANOVA indicate there might be differences among the groups?",
         answer("Yes", correct = TRUE),
         answer("No"),
            random_answer_order = TRUE,
            allow_retry = TRUE,
         correct = "You are amazing!",
         incorrect = "Since _p_ < .05, the results suggest we ought to investigate the difference between at least two groups."
)
```

## Power Analysis

To do a power analysis for a one-way ANOVA is kind of tricky, because you need to
decide what kind of effect size you’re looking for. If you’re mainly interested in the overall
significance test, the sample size needed is a function of the standard deviation of the
group means. Your estimate of the standard deviation of means that you’re looking for
may be based on a pilot experiment or published literature on similar experiments.
If you’re mainly interested in the comparisons of means, there are other ways of
expressing the effect size. Your effect could be a difference between the smallest and
largest means, for example, that you would want to be significant according to a Tukey-Kramer test (see [You found something interesting! Now what?](../sb-one-way-anova/#section-you-found-something-interesting-now-what) earlier in this lesson).

As an example, let’s say you’re studying transcript amount of some gene in these groups:

1. arm muscle    
2. heart muscle    
3. brain    
4. liver    
5. lung 

Based on previous research, you decide that you’d like the ANOVA to be significant if the means are 

1. 10 units in the arm muscle    
2. 10 units in the heart muscle, 
3. 15 units in the brain    
4. 15 units in the liver    
5. 15 units in the lung 

The standard deviation of transcript amount within a tissue type that you’ve seen in previous research is 12 units. 

We have supplied two vectors for the analysis: `group_means`, the means for each group, from which we can derive the between-groups variance, and `experiment_var`, the overall variance for the experiment, or the within-groups variance. See what each vector contains in this next code box.

```{r see_vars, exercise = TRUE, exercise.lines = 5}

```
```{r see_vars-hint}
group_means

```
```{r see_vars-solution}
group_means
experiment_var
```

For an _a priori_ power analysis, the `power.anova.test` function requires the number of groups, the two types of variance (within-groups and between-groups), the alpha level for the experiment, and the required power for the experiment. Many people use an alpha of .05 because it has been popular, but we encourage you to check out our lesson [Reassessing _p_ Values](../sb-reassessing-p-values/) and use one of the alphas proposed by spokespeople for the ASA, .005. 

```{r p-values}
# Define the answer options
choices <- c(
   ".10",
   ".05",
   ".005",
   ".001"
   )
# Initialize the question
question_rank(
   "Rank alphas from least to most stringent.",
   answer(choices, correct = TRUE),
   answer(rev(choices), correct = FALSE, message = "Other direction."),
   allow_retry = TRUE
)
```
```{r which-p-recommended, echo=FALSE}
question("Which _p_ value is recommended by Daniel J. Benjamin and James O. Berger in 'Three Recommendations for Improving the Use of p-Values' in The American Statistician's volume **Beyond _p_ < .05**?",
         answer("p < .10"),
         answer("p < .05"),
         answer("p. < .005", correct = TRUE),
         answer("p < .001"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "Go to this URL and find out: https://amstat.tandfonline.com/doi/full/10.1080/00031305.2018.1543135#.XfPzRi3MzOQ."
)
```

Benjamin and Berger said

>In statistical practice, perhaps the single biggest problem with p-values is that they are often misinterpreted in ways that lead to overstating the evidence against the null hypothesis.

[Find out more!](https://amstat.tandfonline.com/doi/full/10.1080/00031305.2018.1543135#.XfPzni3MzOR)

Perform an analysis with the `power.anova.test` function from the `stats` package. You need to specify the number of groups with the `groups` argument, *within group variance (`experiment_var`)* with the `within.var` argument, *between group variance `var(group_means)`* with the `between.var` argument, the signficiance value with `sig.level` (use a level of .005) and power with `power`. Recall that standard deviation is the square root of variance. 

Store the results of `power.anova.test` in `pwr_results` and surround the entire statement with parentheses so you can see the results as they are stored in the variable. On the next line, type `str(pwr_results)` so you can see the structure of the results and the variable names you can use to access them. 

```{r poweranova, exercise = TRUE, exercise.lines = 5}

```
```{r poweranova-hint-1}
library(stats)
(power_results <- power.anova.test(...))
str(...)
```
```{r poweranova-hint-2}
library(stats)
(power_results <- power.anova.test(groups = 5,
                                   ...))
str(power_results)
```
```{r poweranova-hint-3}
library(stats)
(power_results <- power.anova.test(groups = 5,
                                   within.var = experiment_var,
                                   ...))
str(power_results)
```
```{r poweranova-hint-4}
library(stats)
(power_results <- power.anova.test(groups = 5,
                                   within.var = experiment_var,
                                   between.var = group_means,
                                   ...))
str(power_results)
```
```{r poweranova-solution}
library(stats)
(power_results <- power.anova.test(groups = 5,
                                   within.var = experiment_var,
                                   between.var = var(group_means),
                                   sig.level = .005,
                                   power = 0.80))
str(power_results)
```

```{r what-is-the-var-name, echo=FALSE}
question("What is the variable name for the significance level you set in the previous exercise?",
         answer("`sig_level`", correct = TRUE),
         answer("`pwr_results$sig.level`"),
         answer("`sig`"),
         answer("`alpha`"),
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

*Interpretation*: Since there are `r power_results$groups` groups, you’d need `r power_results$n` observations per group to have an 80% chance of finding a significant result at alpha = `r power_results$sig.level` if an effect is actually there.

Alternatively, if you have no experimental data, you can use the `cohen.ES` function to estimate effect sizes and the `pwr.anova.test` function from the `pwr` package. 

First, put `pwr` in the library.

Next, assign to a variable called `effect_size` the results of a call to `cohen.ES` with the arguments `test` set equal to "anov" and `size` set equal to "small". Add `$effect.size` to that function call so you set `effect_size` equal not to the entire results of the function call, but just to the bit in the results named `effect.size`. It will look odd, but it will work.

Now you can make the call to `pwr.anova.test`. Pass it `k` set equal to 5, `f` set equal to the variable `effect_size` you just made, `sig.level` set equal to .005, and `power` set equal to 0.80.

Run this code and look at the results. 

```{r pwr_anova_test, exercise = TRUE, exercise.lines = 5}

```
```{r pwr_anova_test-hint-1}
library(pwr)
effect_size <- ?
pwr.anova.test(...)
```
```{r pwr_anova_test-hint-2}
library(pwr)
effect_size <- cohen.ES(...)$effect.size
pwr.anova.test(...)
```
```{r pwr_anova_test-hint-3}
library(pwr)
effect_size <- cohen.ES(test = "anov", size = "small")$effect.size
pwr.anova.test(...)
```
```{r pwr_anova_test-hint-4}
library(pwr)
effect_size <- cohen.ES(test = "anov", size = "small")$effect.size
pwr.anova.test(k = 5,
               f = effect_size,
               ...)
```
```{r pwr_anova_test-solution}
library(pwr)
effect_size <- cohen.ES(test = "anov", size = "small")$effect.size
pwr.anova.test(k = 5,
               f = effect_size,
               sig.level = .005,
               power = 0.80)
```

```{r whysolarge, echo=FALSE}
question("Why do you suppose you need so many samples to get the power you want?",
         answer("because p < .005 rather than .05", correct = TRUE),
         answer("because we decided to look for a small effect size", correct = TRUE),
         answer("because we made a mistake"),
         answer("because power analyses are generally irrational"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Your are amazing!"
)
```


## But I like math. Where's the math?

The basic idea is to calculate the mean of the observations within each group, then
compare the variance **among** these means to the average variance **within** each group.

Let's state that slightly differently: Under the null hypothesis that the observations in the different groups all have the same mean, the weighted **among-group** variance will be the same as the **within-group** variance. 

As the means get further apart, the variance **among** the means increases. 

The test statistic is _F_: the ratio of the variance **among** the group means _divided by_ the average variance **within** the groups. 

> $\displaystyle F = \frac{Var_a}{Var_w}$,

where $\displaystyle Var_a = $ variance _among_ group means and $\displaystyle Var_w =$ the average variance _within_ the values in each group.


The $\displaystyle F$ statistic has a known distribution under the null hypothesis, so you can calculate the
probability of obtaining the observed $\displaystyle F$ under the null hypothesis.
The shape of the $\displaystyle F$-distribution depends on two degrees of freedom:

* the degrees of
freedom of the numerator (among-group variance)    
* degrees of freedom of the
denominator (within-group variance). 

The _among-group degrees of freedom_ is the
number of groups minus one. 

The _within-groups degrees of freedom_ is the total number
of observations minus the number of groups. 

If there are $\displaystyle n$ observations in $\displaystyle A$ groups,

* numerator degrees of freedom is $\displaystyle n - 1$     
* denominator degrees of freedom is $\displaystyle n - A$. 

For the
example data set, there are 5 groups and 39 observations, so 

* the numerator degrees of
freedom is $\displaystyle 5 - 1 = 4$      
* the denominator degrees of freedom is $\displaystyle 39 - 5 = 34$. 

In order to check where your results fall under the $\displaystyle F$ distribution, you need three pieces of information (if you are calculating by hand): the value of $\displaystyle \frac{Var_a}{Var_w}$, the numerator degrees of freedom (here 4) and the denominator degrees of freedom (here 34). 

But you can always take the easy way out and use R to calculate your $\displaystyle F$ statistic and its accompanying _p_ value for you. 

## References 

This lesson is heavily based with thanks on the works of John H. McDonald ([Handbook of Biological Statistics](http://www.biostathandbook.com/chigof.html)) and Salvatore S. Mangiafico ([R Companion to the Biostats Handbook](https://rcompanion.org/rcompanion/b_03.html)).

## See Also 

[Kruskall Wallis test](../sb-kruskal-wallis/).
