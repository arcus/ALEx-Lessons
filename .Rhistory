)
# Chunk 7: best
question("What is the BEST situation in which to use a Kruskal-Wallis test?",
answer("When your data ISN'T normal"),
answer("When your data is homoscedastic"),
answer("When your data is actually ranked (a relatively rare occurence)", correct = TRUE),
answer("When your data is normal but the data set is very small")
)
Data <- mutate(Data,
Health = factor(Health, levels = unique(Health)))
# Chunk 1: setup
library(learnr)
library(data.table)
library(dplyr)
library(rcompanion)
library(lattice)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
# Chunk 2: vars
question("You might use an exact test of goodness-of-fit to examine which of the following relationships?",
answer("Height and weight"),
answer("Height, weight, and age group"),
answer("Whether a child uses his right hand more frequently than his left hand", correct = TRUE),
answer("Height, weight, and season")
)
# Chunk 3: why
question("When might you NOT want to use the exact test of goodness-of-fit despite having a single nominal variable?",
answer("When you your data is normally distributed"),
answer("When your data is very large", correct = TRUE),
answer("When your data is NOT normally distributed"),
answer("When you have skewed data")
)
# Chunk 4: rank
question("How do you make ranked data?",
answer("You rate the data on a scale from poor to excellent"),
answer("The smallest measurement is 1, the second smallest is 2, and so on through all the values you have", correct = TRUE),
answer("The largest measurement is 1, the second largest is 2, and so on through all your values"),
answer("You submit your data for IRB review in a contest to see which researcher has the best data")
)
# Chunk 5: hetero
question("Upon which assumptions does the Kruskal-Wallis test rest?",
answer("Normality"),
answer("Inter-related variables"),
answer("Ranking"),
answer("Homoscedasticity and same group distributions", correct = TRUE)
)
# Chunk 6: assumptions
question("Upon what assumptions does the Kruskal-Wallis test NOT rely?",
answer("Normality and homoscedasticity"),
answer("Wechsler test results"),
answer("Packages like dplyr and base stats"),
answer("All of the above", correct = TRUE)
)
# Chunk 7: best
question("What is the BEST situation in which to use a Kruskal-Wallis test?",
answer("When your data ISN'T normal"),
answer("When your data is homoscedastic"),
answer("When your data is actually ranked (a relatively rare occurence)", correct = TRUE),
answer("When your data is normal but the data set is very small")
)
Data
Data <- Muco
Data
names(Data) <- c("Efficiency", "Health")
Data
Data <- mutate(Data,
Health = factor(Health, levels = unique(Health)))
Data
str(Data)
Data <- data(Muco)
Muco
library(rankFD)
Muco
library(learnr)
library(data.table)
library(dplyr)
library(rcompanion)
library(lattice)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
Data <- Muco
names(Data) <- c("Efficiency", "Health")
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
Data <- Muco
names(Data) <- c("Efficiency", "Health")
rm(Muco)
rm(Data)
rm(list = ls())
library(learnr)
library(data.table)
library(dplyr)
library(rcompanion)
library(lattice)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
Data <- Muco
data(Muco)
library(rankFD)
Data <- Muco
??dunnTest
PT <- PT$res
# Chunk 1: setup
library(learnr)
library(data.table)
library(dplyr)
library(rcompanion)
library(lattice)
library(rankFD)
library(FSA)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
Data <- Muco
names(Data) <- c("Efficiency", "Health")
# Chunk 2: vars
question("You might use an exact test of goodness-of-fit to examine which of the following relationships?",
answer("Height and weight"),
answer("Height, weight, and age group"),
answer("Whether a child uses his right hand more frequently than his left hand", correct = TRUE),
answer("Height, weight, and season")
)
# Chunk 3: why
question("When might you NOT want to use the exact test of goodness-of-fit despite having a single nominal variable?",
answer("When you your data is normally distributed"),
answer("When your data is very large", correct = TRUE),
answer("When your data is NOT normally distributed"),
answer("When you have skewed data")
)
# Chunk 4: rank
question("How do you make ranked data?",
answer("You rate the data on a scale from poor to excellent"),
answer("The smallest measurement is 1, the second smallest is 2, and so on through all the values you have", correct = TRUE),
answer("The largest measurement is 1, the second largest is 2, and so on through all your values"),
answer("You submit your data for IRB review in a contest to see which researcher has the best data")
)
# Chunk 5: hetero
question("Upon which assumptions does the Kruskal-Wallis test rest?",
answer("Normality"),
answer("Inter-related variables"),
answer("Ranking"),
answer("Homoscedasticity and same group distributions", correct = TRUE)
)
# Chunk 6: assumptions
question("Upon what assumptions does the Kruskal-Wallis test NOT rely?",
answer("Normality and homoscedasticity"),
answer("Wechsler test results"),
answer("Packages like dplyr and base stats"),
answer("All of the above", correct = TRUE)
)
# Chunk 7: best
question("What is the BEST situation in which to use a Kruskal-Wallis test?",
answer("When your data ISN'T normal"),
answer("When your data is homoscedastic"),
answer("When your data is actually ranked (a relatively rare occurence)", correct = TRUE),
answer("When your data is normal but the data set is very small")
)
# Chunk 9: mutatedata
# Chunk 10: mutatedata-hint-1
Data <- mutate(...,
Health = factor(..., levels = unique(...)))
# Chunk 11: mutatedata-hint-2
Data <- mutate(Data,
Health = factor(Health, levels = unique(...)))
# Chunk 12: mutatedata-solution
Data <- mutate(Data,
Health = factor(Health, levels = unique(Health)))
# Chunk 1: setup
library(learnr)
library(data.table)
library(dplyr)
library(rcompanion)
library(lattice)
library(rankFD)
library(FSA)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
Data <- Muco
names(Data) <- c("Efficiency", "Health")
# Chunk 2: vars
question("You might use an exact test of goodness-of-fit to examine which of the following relationships?",
answer("Height and weight"),
answer("Height, weight, and age group"),
answer("Whether a child uses his right hand more frequently than his left hand", correct = TRUE),
answer("Height, weight, and season")
)
# Chunk 3: why
question("When might you NOT want to use the exact test of goodness-of-fit despite having a single nominal variable?",
answer("When you your data is normally distributed"),
answer("When your data is very large", correct = TRUE),
answer("When your data is NOT normally distributed"),
answer("When you have skewed data")
)
# Chunk 4: rank
question("How do you make ranked data?",
answer("You rate the data on a scale from poor to excellent"),
answer("The smallest measurement is 1, the second smallest is 2, and so on through all the values you have", correct = TRUE),
answer("The largest measurement is 1, the second largest is 2, and so on through all your values"),
answer("You submit your data for IRB review in a contest to see which researcher has the best data")
)
# Chunk 5: hetero
question("Upon which assumptions does the Kruskal-Wallis test rest?",
answer("Normality"),
answer("Inter-related variables"),
answer("Ranking"),
answer("Homoscedasticity and same group distributions", correct = TRUE)
)
# Chunk 6: assumptions
question("Upon what assumptions does the Kruskal-Wallis test NOT rely?",
answer("Normality and homoscedasticity"),
answer("Wechsler test results"),
answer("Packages like dplyr and base stats"),
answer("All of the above", correct = TRUE)
)
# Chunk 7: best
question("What is the BEST situation in which to use a Kruskal-Wallis test?",
answer("When your data ISN'T normal"),
answer("When your data is homoscedastic"),
answer("When your data is actually ranked (a relatively rare occurence)", correct = TRUE),
answer("When your data is normal but the data set is very small")
)
# Chunk 9: mutatedata
# Chunk 10: mutatedata-hint-1
Data <- mutate(...,
Health = factor(..., levels = unique(...)))
# Chunk 11: mutatedata-hint-2
Data <- mutate(Data,
Health = factor(Health, levels = unique(...)))
# Chunk 12: mutatedata-solution
Data <- mutate(Data,
Health = factor(Health, levels = unique(Health)))
Data
str(Data)
PT
### Order groups by median
Data$Health <- factor(Data$Health,
levels=c("OAD", "Normal", "Asbestosis"))
### Run the Dunn test
PT = dunnTest(Efficiency ~ Health,
data=Data,
method="bh")    # Can adjust p-values;
# See ?p.adjust for options
## See the results
PT
PT <- PT$res
PT
cldList(comparison = PT$Comparison,
p.value    = PT$P.adj,
threshold  = 0.05)
try(cldList(comparison = PT$Comparison,
p.value    = PT$P.adj,
threshold  = 0.05))
rm(list = ls)
rm(list = ls())
rm(ls())
install.packages('rsconnect')
rsconnect::setAccountInfo(name='chop-arcus', token='4B8DBBDDE1B4778F304E2B2F0BF45727', secret='nipiQVkor0H0RL4Tj4BFjIw+Zf1Qn7uHW0JAiBNg')
library(FSA)
library(learnr)
library(learnr)
options(scipen = 9999)
tutorial_options(exercise.startover = TRUE,
exercise.eval = TRUE,
exercise.cap = "R Code",
exercise.completion = TRUE,
exercise.diagnostics = TRUE)
if(!require(learnr)){install.packages("learnr")}
if(!require(psych)){install.packages("psych")}
if(!require(rcompanion)){install.packages("rcompanion")}
if(!require(lsr)){install.packages("lsr")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(tidyverse)){install.packages("tidyverse")}
df <- as_tibble(cbind(c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J"), c(120.6, 116.4, 117.2, 118.1, 114.1, 116.9, 113.3, 121.1, 116.9, 117.0)))
names(df) <- c("Individual", "Angle")
df$Angle <- as.numeric(df$Angle)
(mean_guess <- mean(df$Angle))
Input = ("
Instructor     Student     Sodium
'Brendon Small'     a     1200
'Brendon Small'     b     1400
'Brendon Small'     c     1350
'Brendon Small'     d     950
'Brendon Small'     e     1400
'Brendon Small'     f     1150
'Brendon Small'     g     1300
'Brendon Small'     h     1325
'Brendon Small'     i     1425
'Brendon Small'     j     1500
'Brendon Small'     k     1250
'Brendon Small'     l     1150
'Brendon Small'     m     950
'Brendon Small'     n     1150
'Brendon Small'     o     1600
'Brendon Small'     p     1300
'Brendon Small'     q     1050
'Brendon Small'     r     1300
'Brendon Small'     s     1700
'Brendon Small'     t     1300
")
sodium = as_tibble(read.table(textConnection(Input), header=TRUE))
rm(Input)
wpm_Input = ("
Instructor     Student     words_per_minute
'Dr. Katz Professional Therapist'     a     35
'Dr. Katz Professional Therapist'     b     50
'Dr. Katz Professional Therapist'     c     55
'Dr. Katz Professional Therapist'     d     60
'Dr. Katz Professional Therapist'     e     65
'Dr. Katz Professional Therapist'     f     60
'Dr. Katz Professional Therapist'     g     70
'Dr. Katz Professional Therapist'     h     55
'Dr. Katz Professional Therapist'     i     45
'Dr. Katz Professional Therapist'     j     55
'Dr. Katz Professional Therapist'     k     60
'Dr. Katz Professional Therapist'     l     45
'Dr. Katz Professional Therapist'     m     65
'Dr. Katz Professional Therapist'     n     55
'Dr. Katz Professional Therapist'     o     50
'Dr. Katz Professional Therapist'     p     60
")
wpm = as_tibble(read.table(textConnection(wpm_Input),header=TRUE))
rm(wpm_Input)
muknee <- 120
muNa <- 1500
muwpm <- 40
xNa <- sodium$Sodium
xwpm <- wpm$words_per_minute
df
xNa <- sodium$Sodium
library(psych)
headTail(xNa)
str(xNa)
summary(xNa)
library(rcompanion)
plotNormalHistogram(xNa)
qqnorm(xNa)
qqline(xNa, col = "red")
muNa <- 1500 # theoretical mean
t.test(xNa,
mu = muNa,
conf.int = 0.95)
xwpm <- wpm$words_per_minute
library(psych)
headTail(xwpm)
str(xwpm)
summary(xwpm)
xwpm <- wpm$words_per_minute
library(rcompanion)
plotNormalHistogram(xwpm)
qqnorm(xwpm)
qqline(xwpm, col = "green")
muwpm <- 40
t.test(xwpm,
mu = muwpm,
conf.int = 0.95)
library(lsr)
cohensD(sodium$Sodium, 1500)
sd(sodium$Sodium)
cohensD(wpm$words_per_minute, muwpm)
cohensD(sodium$Sodium, muNa)
library(ggplot2)
ggplot(data=sodium,
aes(x = Instructor, y = Sodium)) +
geom_boxplot() +
geom_point(aes(x = 1, y = 1500),
colour="blue",
size = 8,
shape = "+") +
theme_bw() +
theme(axis.title = element_text(face = "bold")) +
theme(axis.text = element_text(face = "bold"))
library(ggplot2)
ggplot(data=wpm,
aes(x = Instructor, y = words_per_minute)) +
geom_boxplot() +
geom_point(aes(x = 1, y = 40),
colour="blue",
size = 8,
shape = "+") +
theme_minimal() +
theme(axis.title = element_text(face = "bold")) +
theme(axis.text = element_text(face = "bold")) +
labs(y = "Words per Minute")
library(tidyverse)
library(nycflights13)
flights
view(flights)
library(tidyverse)
library(nycflights13)
library(learnr)
library(data.table)
library(dplyr)
library(pwr)
library(tidyr)
library(stats)
library(ggplot2)
library(sortable)
shhh <- suppressPackageStartupMessages
shh <- suppressWarnings
sh <- suppressMessages
knitr::opts_chunk$set(echo = FALSE)
options(digits = 3, scipen = 9999)
tutorial_options(exercise.completion = FALSE,
exercise.eval = TRUE,
exercise.lines = 8,
exercise.diagnostics = TRUE)
############################### Data for this lesson ###########################################
math <- read.csv("math.csv")
lang <- read.csv("lang.csv")
mathr <- rename(.data = math, id = subjectID, date = testDate, score = mathScore)
langr <- rename(.data = lang, id = subjectID, date = testDate, score = languageScore)
df <- merge(mathr, langr, by = "id", suffixes = c("_math", "_lang"))
earliest_math <- as_tibble(merge(x = mathr,
y = langr,
by = "id",
all.x = TRUE,
suffixes = c("_math", "_lang")))
df$date_diff <- abs(as.Date(df$date_lang) - as.Date(df$date_math))
closest_pairs <- as_tibble(df %>%
group_by(id) %>%
filter(date_diff == min(date_diff)) %>%
slice(1) %>%
ungroup)
first_math_maybe_language <- as_tibble(earliest_math %>%
group_by(id) %>%
filter(abs(date_lang - date_math)
== min(abs(date_lang - date_math)) |
is.na(date_lang - date_math)) %>%
slice(1) %>%
ungroup)
library(rmarkdown)
library(shiny)
library(knitr)
knitr::include_graphics("www/fig1.png")
ToRender <- rbind(c("1","CHROM","Chromosome of the variant"),
c("2","POS","1-based position of the start of the variant"),
c("3","ID","Unique identifier of the variant, if any"),
c("4","REF","The reference allele at that position"),
c("5","ALT","The alternative allele identified at that position in the subject"),
c("6","QUAL","The PHRED quality of the call of the allele"),
c("7","FILTER","Site filtering information"),
c("8","INFO","Semicolon delimited field that can be customized to the user's needs"),
c("9","FORMAT","Colon delimited field that defines the information contained within each subsequent genotype column"),
c("10+","Samples","Genotype information for one or multiple samples in the format defined in FORMAT")
)
ToRender <- as.data.frame(ToRender)
colnames(ToRender) <- c("Number","Field Name","Description")
kable(ToRender)
ToRender <- rbind(c("-c","Standard out","Write to standard out"),
c("-d","Decompress","Decompress a .vcf.gz file"),
c("--threads N","Threads","Use N threads for compression (faster)"))
ToRender <- as.data.frame(ToRender)
colnames(ToRender) <- c("Option","Name","Description")
kable(ToRender)
ToRender <- rbind(c("-Ob","Output","Defines the output format. Ob for BCF, Ov for VCF"),
c("-o","Output file","Define the output file location. Otherwise outputs to standard out"),
c("--use-header Sample1.vcf.gz","Header","Use the header contained in the specified file."))
ToRender <- as.data.frame(ToRender)
colnames(ToRender) <- c("Option","Name","Description")
kable(ToRender)
ToRender <- rbind(c("%CHROM","The CHROM column (similarly also other columns: POS, ID, REF, ALT, QUAL, FILTER)"),
c("%END","End position of the REF allele"),
c("%END0","End position of the REF allele in 0-based coordinates"),
c("%FIRST_ALT","Alias for %ALT{0}"),
c("%FORMAT","Prints all FORMAT fields or a subset of samples with -s or -S"),
c("%GT","Genotype (e.g. 0/1)"),
c("%INFO","Prints the whole INFO column"),
c("%INFO/TAG","Any tag in the INFO column"),
c("%IUPACGT","Genotype translated to IUPAC ambiguity codes (e.g. M instead of C/A)"),
c("%LINE","Prints the whole line"),
c("%MASK","Indicates presence of the site in other files (with multiple files)"),
c("%POS0","POS in 0-based coordinates"),
c("%PBINOM(TAG)","Calculate phred-scaled binomial probability, the allele index is determined from GT"),
c("%SAMPLE","Sample name"),
c("%TAG{INT}","Curly brackets to print a subfield (e.g. INFO/TAG{1}, the indexes are 0-based)"),
c("%TBCSQ","Translated FORMAT/BCSQ. See the csq command above for explanation and examples."),
c("%TGT","Translated genotype (e.g. C/A)"),
c("%TYPE","Variant type (REF, SNP, MNP, INDEL, BND, OTHER)"),
c("[]","Format fields must be enclosed in brackets to loop over all samples"),
c("\\\\n","new line"),
c("\\\\t","tab character"))
ToRender <- as.data.frame(ToRender)
colnames(ToRender) <- c("Variable","Description")
kable(ToRender)
View(ToRender)
scores
knitr::opts_chunk$set(echo = FALSE)
#library(rmarkdown)
#library(shiny)
library(knitr)
